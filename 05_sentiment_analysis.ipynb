{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iBJxV7kqcxhz",
    "outputId": "7db481ea-d72b-4848-d29c-dc22106ae61d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.display import Image, display\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "import re\n",
    "import codecs\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Устанавливаю необходимые библиотеки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda config --append channels conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/olgakalinina/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pymorphy2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.12.0               |   py39hecd8cb5_0        14.5 MB\n",
      "    dawg-python-0.7.2          |     pyhd8ed1ab_0          12 KB  conda-forge\n",
      "    docopt-0.6.2               |   py39hecd8cb5_0          24 KB\n",
      "    pymorphy2-0.9.1            |     pyhd8ed1ab_0          44 KB  conda-forge\n",
      "    pymorphy2-dicts-ru-2.4.417127.4579844|     pyhd8ed1ab_0         7.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        21.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  dawg-python        conda-forge/noarch::dawg-python-0.7.2-pyhd8ed1ab_0\n",
      "  docopt             pkgs/main/osx-64::docopt-0.6.2-py39hecd8cb5_0\n",
      "  pymorphy2          conda-forge/noarch::pymorphy2-0.9.1-pyhd8ed1ab_0\n",
      "  pymorphy2-dicts-ru conda-forge/noarch::pymorphy2-dicts-ru-2.4.417127.4579844-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.11.0-py39hecd8cb5_0 --> 4.12.0-py39hecd8cb5_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pymorphy2-0.9.1      | 44 KB     | ##################################### | 100% \n",
      "conda-4.12.0         | 14.5 MB   | ##################################### | 100% \n",
      "dawg-python-0.7.2    | 12 KB     | ##################################### | 100% \n",
      "pymorphy2-dicts-ru-2 | 7.1 MB    | ##################################### | 100% \n",
      "docopt-0.6.2         | 24 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  /Users/olgakalinina/opt/anaconda3/bin/python -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  /Users/olgakalinina/opt/anaconda3/bin/python -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  /Users/olgakalinina/opt/anaconda3/bin/python -m pip install [options] [-e] <vcs project url> ...\n",
      "  /Users/olgakalinina/opt/anaconda3/bin/python -m pip install [options] [-e] <local project path> ...\n",
      "  /Users/olgakalinina/opt/anaconda3/bin/python -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install --upgrade pip -m /Users/olgakalinina/opt/anaconda3/lib/python3.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/olgakalinina/opt/anaconda3/lib/python3.9/site-packages (22.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzHcJiO_cxh1"
   },
   "source": [
    "---\n",
    "\n",
    "## Семантический анализ твитов\n",
    "\n",
    "Сегодня мы построим классификатор, который будет разделять текст на позитивные и негативные высказывания. Для этого мы воспользуемся уже размеченной базой.\n",
    "Загрузим данные для анализа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvWtVri3t5fD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l9xDxvzacxh3",
    "outputId": "617ab205-392d-423f-d40c-abac3a53fa64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>rep</th>\n",
       "      <th>rtv</th>\n",
       "      <th>fav</th>\n",
       "      <th>total_count</th>\n",
       "      <th>fol</th>\n",
       "      <th>friends</th>\n",
       "      <th>list_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408906854803451904</td>\n",
       "      <td>1386325965</td>\n",
       "      <td>fantanshik</td>\n",
       "      <td>RT @Abdullin_A_R: @LikhodedovaMary эхх, а в УГ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2074</td>\n",
       "      <td>82</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>408906854849204224</td>\n",
       "      <td>1386325965</td>\n",
       "      <td>Tienn_En</td>\n",
       "      <td>@marinaysol а, а то подумала, что у тебя там п...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6362</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>408906855146983424</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>bstrd666</td>\n",
       "      <td>@xLesherx @4EU3 зря вы с этой хуйней шутите)) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13431</td>\n",
       "      <td>473</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>408906857659392000</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>esken_h</td>\n",
       "      <td>@Moscow_advokat Очень главное спасибо for   МЕ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126795</td>\n",
       "      <td>581</td>\n",
       "      <td>86</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>408906857982726080</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>Obrazcova98</td>\n",
       "      <td>У нас есть прекрасная история, как сдохнуть за...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>408906762813579328</td>\n",
       "      <td>1386325944</td>\n",
       "      <td>dugarchikbellko</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8064</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>408906818262687680</td>\n",
       "      <td>1386325957</td>\n",
       "      <td>nugemycejela</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>408906858515398720</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>4post21</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>408906914437685184</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>Poliwake</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10628</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>408906914723295232</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>capyvixowe</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        date             name  \\\n",
       "16  408906854803451904  1386325965       fantanshik   \n",
       "17  408906854849204224  1386325965         Tienn_En   \n",
       "18  408906855146983424  1386325966         bstrd666   \n",
       "19  408906857659392000  1386325966          esken_h   \n",
       "20  408906857982726080  1386325966      Obrazcova98   \n",
       "21  408906762813579328  1386325944  dugarchikbellko   \n",
       "22  408906818262687680  1386325957     nugemycejela   \n",
       "23  408906858515398720  1386325966          4post21   \n",
       "24  408906914437685184  1386325980         Poliwake   \n",
       "25  408906914723295232  1386325980       capyvixowe   \n",
       "\n",
       "                                                 text  positive  rep  rtv  \\\n",
       "16  RT @Abdullin_A_R: @LikhodedovaMary эхх, а в УГ...         1    0    1   \n",
       "17  @marinaysol а, а то подумала, что у тебя там п...         1    0    0   \n",
       "18  @xLesherx @4EU3 зря вы с этой хуйней шутите)) ...         1    0    0   \n",
       "19  @Moscow_advokat Очень главное спасибо for   МЕ...         1    0    0   \n",
       "20  У нас есть прекрасная история, как сдохнуть за...         1    0    0   \n",
       "21  на работе был полный пиддес :| и так каждое за...        -1    0    0   \n",
       "22  Коллеги сидят рубятся в Urban terror, а я из-з...        -1    0    0   \n",
       "23  @elina_4post как говорят обещаного три года жд...        -1    0    0   \n",
       "24  Желаю хорошего полёта и удачной посадки,я буду...        -1    0    0   \n",
       "25  Обновил за каким-то лешим surf, теперь не рабо...        -1    0    0   \n",
       "\n",
       "    fav  total_count  fol  friends  list_count  \n",
       "16    0         2074   82       44           5  \n",
       "17    0         6362   30       28           1  \n",
       "18    0        13431  473      111           2  \n",
       "19    0       126795  581       86          10  \n",
       "20    0          492   14       23           0  \n",
       "21    0         8064  111       94           2  \n",
       "22    0           26   42       39           0  \n",
       "23    0          718   49      249           0  \n",
       "24    0        10628  207      200           0  \n",
       "25    0           35   17       34           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data-samples/tweets_example.xlsx')\n",
    "df.loc[16:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LPhxl7Ucxh3"
   },
   "source": [
    "---\n",
    "\n",
    "Все колонки таблицы могут содержать информацию о тональности твита, но мы будем ориентироваться исключительно на текст и на столбец отнесения к классу positiv.\n",
    "Заменим значение -1 в колонке positive на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6VBRASFNcxh4",
    "outputId": "1c2f5a7a-2607-4314-de5e-dd2574ba4433"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>rep</th>\n",
       "      <th>rtv</th>\n",
       "      <th>fav</th>\n",
       "      <th>total_count</th>\n",
       "      <th>fol</th>\n",
       "      <th>friends</th>\n",
       "      <th>list_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408906854803451904</td>\n",
       "      <td>1386325965</td>\n",
       "      <td>fantanshik</td>\n",
       "      <td>RT @Abdullin_A_R: @LikhodedovaMary эхх, а в УГ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2074</td>\n",
       "      <td>82</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>408906854849204224</td>\n",
       "      <td>1386325965</td>\n",
       "      <td>Tienn_En</td>\n",
       "      <td>@marinaysol а, а то подумала, что у тебя там п...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6362</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>408906855146983424</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>bstrd666</td>\n",
       "      <td>@xLesherx @4EU3 зря вы с этой хуйней шутите)) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13431</td>\n",
       "      <td>473</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>408906857659392000</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>esken_h</td>\n",
       "      <td>@Moscow_advokat Очень главное спасибо for   МЕ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126795</td>\n",
       "      <td>581</td>\n",
       "      <td>86</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>408906857982726080</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>Obrazcova98</td>\n",
       "      <td>У нас есть прекрасная история, как сдохнуть за...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>408906762813579328</td>\n",
       "      <td>1386325944</td>\n",
       "      <td>dugarchikbellko</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8064</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>408906818262687680</td>\n",
       "      <td>1386325957</td>\n",
       "      <td>nugemycejela</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>408906858515398720</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>4post21</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>408906914437685184</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>Poliwake</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10628</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>408906914723295232</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>capyvixowe</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        date             name  \\\n",
       "16  408906854803451904  1386325965       fantanshik   \n",
       "17  408906854849204224  1386325965         Tienn_En   \n",
       "18  408906855146983424  1386325966         bstrd666   \n",
       "19  408906857659392000  1386325966          esken_h   \n",
       "20  408906857982726080  1386325966      Obrazcova98   \n",
       "21  408906762813579328  1386325944  dugarchikbellko   \n",
       "22  408906818262687680  1386325957     nugemycejela   \n",
       "23  408906858515398720  1386325966          4post21   \n",
       "24  408906914437685184  1386325980         Poliwake   \n",
       "25  408906914723295232  1386325980       capyvixowe   \n",
       "\n",
       "                                                 text  positive  rep  rtv  \\\n",
       "16  RT @Abdullin_A_R: @LikhodedovaMary эхх, а в УГ...         1    0    1   \n",
       "17  @marinaysol а, а то подумала, что у тебя там п...         1    0    0   \n",
       "18  @xLesherx @4EU3 зря вы с этой хуйней шутите)) ...         1    0    0   \n",
       "19  @Moscow_advokat Очень главное спасибо for   МЕ...         1    0    0   \n",
       "20  У нас есть прекрасная история, как сдохнуть за...         1    0    0   \n",
       "21  на работе был полный пиддес :| и так каждое за...         0    0    0   \n",
       "22  Коллеги сидят рубятся в Urban terror, а я из-з...         0    0    0   \n",
       "23  @elina_4post как говорят обещаного три года жд...         0    0    0   \n",
       "24  Желаю хорошего полёта и удачной посадки,я буду...         0    0    0   \n",
       "25  Обновил за каким-то лешим surf, теперь не рабо...         0    0    0   \n",
       "\n",
       "    fav  total_count  fol  friends  list_count  \n",
       "16    0         2074   82       44           5  \n",
       "17    0         6362   30       28           1  \n",
       "18    0        13431  473      111           2  \n",
       "19    0       126795  581       86          10  \n",
       "20    0          492   14       23           0  \n",
       "21    0         8064  111       94           2  \n",
       "22    0           26   42       39           0  \n",
       "23    0          718   49      249           0  \n",
       "24    0        10628  207      200           0  \n",
       "25    0           35   17       34           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.positive[df.positive==-1]=0\n",
    "df.loc[16:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJ6Uu0l_cxh5"
   },
   "source": [
    "### Очистка и предобработка данных\n",
    "\n",
    "Перед разработкой классификатора нам необходимо очистить и предобработать данные.\n",
    "\n",
    "Начнем с очистки данных\n",
    "\n",
    "----------------------------\n",
    "\n",
    "***Внимание!*** Библиотека [*nltk*](https://www.nltk.org) может содержать не все компоненты. В случае возникновения ошибки необходимо запустить скрипт\n",
    "\n",
    "*import nltk   \n",
    "nltk.download()*\n",
    "\n",
    "В открывшемся окне необходимо выбрать и установить требуемые компоненты\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим БД с позитивными твитами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=pd.read_csv('../datasets/positive.csv', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим БД с негативными твитами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg=pd.read_csv('../datasets/negative.csv', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.concat([pos, neg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переименуем название столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=result.rename(columns={0 : 'id', 1 : 'date', 2: 'name', 3: 'text', 4: 'positive', 5: 'rep', 6: 'rtv', 7: 'fav', 8: 'total_count', 9: 'fol', 10: 'friends', 11: 'list_count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько всего твитов, сколько из них - негативных, сколько - позитивных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents= {'twits': result.id.count(), 'positive': result.query(\"positive==1\").agg(\"positive\").count(), 'negative': result.query(\"positive==-1\").agg(\"positive\").count()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twits</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226834</td>\n",
       "      <td>114911</td>\n",
       "      <td>111923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    twits  positive  negative\n",
       "0  226834    114911    111923"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(contents, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если твит позитивный, то значение колонки positive = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.positive[result.positive==-1]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlMO4_7icxiE"
   },
   "source": [
    "Произведем очистку данных\n",
    "\n",
    "----\n",
    "\n",
    "***Совет:*** сохраняйте промежуточные результаты очистки, чтобы в случае неверных действий на каком-либо этапе не пересчитывать все предыдущие этапы\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменяю заглавные буквы на строчные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    @moscow_advokat очень главное спасибо for   ме...\n",
       "20    у нас есть прекрасная история, как сдохнуть за...\n",
       "21    @benjamin1610 сегодня столько поводов выпить, ...\n",
       "22    @stalingulag унылый?...наверное...вдруг его пе...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.text = result.text.str.lower()\n",
    "result.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберу латинские буквы и оставлю только кириллицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19                    очень главное спасибо       ме...\n",
       "20    у нас есть прекрасная история  как сдохнуть за...\n",
       "21                  сегодня столько поводов выпить  ...\n",
       "22                 унылый    наверное   вдруг его пе...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.text = result.text.str.replace(r\"[^А-Яа-я]\",\" \")\n",
    "result.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один твит разделю на несколько слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    [очень, главное, спасибо, медвед, он, работал,...\n",
       "20    [у, нас, есть, прекрасная, история, как, сдохн...\n",
       "21    [сегодня, столько, поводов, выпить, что, я, уж...\n",
       "22    [унылый, наверное, вдруг, его, перед, этим, чп...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "result.text = list(map(word_tokenize, result.text))\n",
    "result.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найду стоп-слова - слова, которые не несут смысловой нагрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['а',\n",
       " 'без',\n",
       " 'более',\n",
       " 'больше',\n",
       " 'будет',\n",
       " 'будто',\n",
       " 'бы',\n",
       " 'был',\n",
       " 'была',\n",
       " 'были',\n",
       " 'было',\n",
       " 'быть',\n",
       " 'в',\n",
       " 'вам',\n",
       " 'вас',\n",
       " 'вдруг',\n",
       " 'ведь',\n",
       " 'во',\n",
       " 'вот',\n",
       " 'впрочем',\n",
       " 'все',\n",
       " 'всегда',\n",
       " 'всего',\n",
       " 'всех',\n",
       " 'всю',\n",
       " 'вы',\n",
       " 'где',\n",
       " 'да',\n",
       " 'даже',\n",
       " 'два',\n",
       " 'для',\n",
       " 'до',\n",
       " 'другой',\n",
       " 'его',\n",
       " 'ее',\n",
       " 'ей',\n",
       " 'ему',\n",
       " 'если',\n",
       " 'есть',\n",
       " 'еще',\n",
       " 'ж',\n",
       " 'же',\n",
       " 'за',\n",
       " 'зачем',\n",
       " 'здесь',\n",
       " 'и',\n",
       " 'из',\n",
       " 'или',\n",
       " 'им',\n",
       " 'иногда',\n",
       " 'их',\n",
       " 'к',\n",
       " 'как',\n",
       " 'какая',\n",
       " 'какой',\n",
       " 'когда',\n",
       " 'конечно',\n",
       " 'кто',\n",
       " 'куда',\n",
       " 'ли',\n",
       " 'лучше',\n",
       " 'между',\n",
       " 'меня',\n",
       " 'мне',\n",
       " 'много',\n",
       " 'может',\n",
       " 'можно',\n",
       " 'мой',\n",
       " 'моя',\n",
       " 'мы',\n",
       " 'на',\n",
       " 'над',\n",
       " 'надо',\n",
       " 'наконец',\n",
       " 'нас',\n",
       " 'не',\n",
       " 'него',\n",
       " 'нее',\n",
       " 'ней',\n",
       " 'нельзя',\n",
       " 'нет',\n",
       " 'ни',\n",
       " 'нибудь',\n",
       " 'никогда',\n",
       " 'ним',\n",
       " 'них',\n",
       " 'ничего',\n",
       " 'но',\n",
       " 'ну',\n",
       " 'о',\n",
       " 'об',\n",
       " 'один',\n",
       " 'он',\n",
       " 'она',\n",
       " 'они',\n",
       " 'опять',\n",
       " 'от',\n",
       " 'перед',\n",
       " 'по',\n",
       " 'под',\n",
       " 'после',\n",
       " 'потом',\n",
       " 'потому',\n",
       " 'почти',\n",
       " 'при',\n",
       " 'про',\n",
       " 'раз',\n",
       " 'разве',\n",
       " 'с',\n",
       " 'сам',\n",
       " 'свою',\n",
       " 'себе',\n",
       " 'себя',\n",
       " 'сейчас',\n",
       " 'со',\n",
       " 'совсем',\n",
       " 'так',\n",
       " 'такой',\n",
       " 'там',\n",
       " 'тебя',\n",
       " 'тем',\n",
       " 'теперь',\n",
       " 'то',\n",
       " 'тогда',\n",
       " 'того',\n",
       " 'тоже',\n",
       " 'только',\n",
       " 'том',\n",
       " 'тот',\n",
       " 'три',\n",
       " 'тут',\n",
       " 'ты',\n",
       " 'у',\n",
       " 'уж',\n",
       " 'уже',\n",
       " 'хорошо',\n",
       " 'хоть',\n",
       " 'чего',\n",
       " 'чем',\n",
       " 'через',\n",
       " 'что',\n",
       " 'чтоб',\n",
       " 'чтобы',\n",
       " 'чуть',\n",
       " 'эти',\n",
       " 'этого',\n",
       " 'этой',\n",
       " 'этом',\n",
       " 'этот',\n",
       " 'эту',\n",
       " 'я']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.sort()\n",
    "russian_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалю стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    [очень, главное, спасибо, медвед, работал, кло...\n",
       "20              [прекрасная, история, сдохнуть, неделю]\n",
       "21    [сегодня, столько, поводов, выпить, могу, усид...\n",
       "22                   [унылый, наверное, этим, чпокнули]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete_stopword(words):\n",
    "    global russian_stopwords\n",
    "    new_s = [word for word in words if word not in russian_stopwords]\n",
    "    return new_s\n",
    "\n",
    "result.text = list(map(delete_stopword, result.text))\n",
    "result.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведу лемматизацию, то есть приведу слова к начальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    [очень, главное, спасибо, медведа, работать, к...\n",
       "20              [прекрасный, история, сдохнуть, неделя]\n",
       "21    [сегодня, столько, повод, выпить, мочь, усидет...\n",
       "22                    [унылый, наверное, это, чпокнуль]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatization(words):\n",
    "    global morph\n",
    "    new_s = [morph.parse(word)[0].normal_form for word in words]\n",
    "    return new_s\n",
    "\n",
    "result.text = list(map(lemmatization, result.text))\n",
    "result.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляю слова, которые встречаются один раз, так как они не смогут помочь предсказать позитивный или негативный твит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    очень главное спасибо медведа работать клоун а...\n",
       "20                   прекрасный история сдохнуть неделя\n",
       "21      сегодня столько повод выпить мочь усидеть место\n",
       "22                                  унылый наверное это\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "def to_str(s):\n",
    "    new_s = ' '.join(j for j in s)\n",
    "    return new_s\n",
    "\n",
    "text_tokens = word_tokenize(' '.join(j for j in list(map(to_str, result.text))))\n",
    "text = nltk.Text(text_tokens)\n",
    "fdist = FreqDist(text)\n",
    "words_to_del = list(filter(lambda k: fdist[k] == 1, fdist))\n",
    "\n",
    "def delete_word(words):\n",
    "    global words_to_del\n",
    "    new_s = [word for word in words if word not in words_to_del]\n",
    "    return new_s\n",
    "\n",
    "result.text = list(map(delete_word, result.text))\n",
    "result.text = list(map(to_str, result.text))\n",
    "result.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найду количество слов до очистки, количество уникальных слов, количество слов после очистки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1493275, 53568, 1439707)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_tokens), len(words_to_del), len(text_tokens) - len(words_to_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найду количество пустых твитов, из них позитивные -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 382)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[result.text == '']), len(result[(result.text == '') & (result.positive == 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалю пустые твиты и посмотрю, сколько всего осталось твитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225978"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.drop(result[result.text == ''].index, axis = 0)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILZT8JtBcxiJ"
   },
   "source": [
    "---\n",
    "\n",
    "Кодирую данные методом мешка слов и TF-IDF, построю классификатор на осонове логистической регресии и случайного леса и сравню результаты\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(result.text, result.positive, test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирую данные с помощью мешка слов и tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv_train = cv.fit_transform(X_train)\n",
    "cv_test = cv.transform(X_test)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построю классификатор, используя логистическую регрессию и кодировку методом мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71     33422\n",
      "           1       0.72      0.73      0.72     34372\n",
      "\n",
      "    accuracy                           0.72     67794\n",
      "   macro avg       0.72      0.72      0.72     67794\n",
      "weighted avg       0.72      0.72      0.72     67794\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79     78027\n",
      "           1       0.80      0.80      0.80     80157\n",
      "\n",
      "    accuracy                           0.80    158184\n",
      "   macro avg       0.80      0.80      0.80    158184\n",
      "weighted avg       0.80      0.80      0.80    158184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=21)\n",
    "lr.fit(cv_train, y_train)\n",
    "cv_pred = lr.predict(cv_test)\n",
    "print('test')\n",
    "print(classification_report(y_test, cv_pred))\n",
    "print('train')\n",
    "print(classification_report(y_train, lr.predict(cv_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построю классификатор, используя логистическую регрессию и кодировку методом TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71     33422\n",
      "           1       0.71      0.75      0.73     34372\n",
      "\n",
      "    accuracy                           0.72     67794\n",
      "   macro avg       0.72      0.72      0.72     67794\n",
      "weighted avg       0.72      0.72      0.72     67794\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77     78027\n",
      "           1       0.77      0.80      0.79     80157\n",
      "\n",
      "    accuracy                           0.78    158184\n",
      "   macro avg       0.78      0.78      0.78    158184\n",
      "weighted avg       0.78      0.78      0.78    158184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=21)\n",
    "lr.fit(tfidf_train, y_train)\n",
    "tfidf_pred = lr.predict(tfidf_test)\n",
    "print('test')\n",
    "print(classification_report(y_test, tfidf_pred))\n",
    "print('train')\n",
    "print(classification_report(y_train, lr.predict(tfidf_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построю классификатор, используя случайный лес и кодировку методом мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72     33422\n",
      "           1       0.74      0.65      0.69     34372\n",
      "\n",
      "    accuracy                           0.70     67794\n",
      "   macro avg       0.71      0.70      0.70     67794\n",
      "weighted avg       0.71      0.70      0.70     67794\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     78027\n",
      "           1       1.00      1.00      1.00     80157\n",
      "\n",
      "    accuracy                           1.00    158184\n",
      "   macro avg       1.00      1.00      1.00    158184\n",
      "weighted avg       1.00      1.00      1.00    158184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=250, n_jobs=-1, random_state=21)\n",
    "forest.fit(cv_train, y_train)\n",
    "cv_pred = forest.predict(cv_test)\n",
    "print('test')\n",
    "print(classification_report(y_test, cv_pred))\n",
    "print('train')\n",
    "print(classification_report(y_train, forest.predict(cv_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построю классификатор, используя случайный лес и кодировку методом TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71     33422\n",
      "           1       0.72      0.74      0.73     34372\n",
      "\n",
      "    accuracy                           0.72     67794\n",
      "   macro avg       0.72      0.72      0.72     67794\n",
      "weighted avg       0.72      0.72      0.72     67794\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     78027\n",
      "           1       1.00      1.00      1.00     80157\n",
      "\n",
      "    accuracy                           1.00    158184\n",
      "   macro avg       1.00      1.00      1.00    158184\n",
      "weighted avg       1.00      1.00      1.00    158184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest.fit(tfidf_train, y_train)\n",
    "tfidf_pred = forest.predict(tfidf_test)\n",
    "print('test')\n",
    "print(classification_report(y_test, tfidf_pred))\n",
    "print('train')\n",
    "print(classification_report(y_train, forest.predict(tfidf_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получили, что, несмотря на использованный метод и кодировку, результаты получились одинаковыми."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "d06_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
